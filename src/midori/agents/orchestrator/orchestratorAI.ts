/**
 * üé≠ Unified Orchestrator AI
 * ‡∏£‡∏ß‡∏° Chat AI + Multi-Agent Orchestrator ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
 * 
 * Capabilities:
 * - Natural language processing
 * - Intent detection (chat vs task)
 * - Command translation
 * - Multi-agent coordination
 * - Task planning & execution
 * - Real-time communication
 */

import { LLMAdapter } from './adapters/llmAdapter';
import { run as legacyOrchestrator } from './runners/run';
import { ChatPromptLoader } from './prompts/chatPromptLoader';
import { getResponseConfig, toLLMOptions } from './configs/responseConfig';
import { randomUUID } from 'crypto';

// Create singleton instance
const chatPromptLoader = ChatPromptLoader.getInstance();

// Types
export interface UserMessage {
  content: string;
  userId: string;
  sessionId?: string;
  timestamp: string;
  context?: ConversationContext;
}

export interface ConversationContext {
  previousMessages: string[];
  currentProject?: string;
  activeAgents: string[];
  lastTaskResult?: any;
}

export interface OrchestratorResponse {
  type: 'chat' | 'task' | 'mixed';
  content: string;
  taskResults?: any;
  nextSteps?: string[];
  metadata: {
    executionTime: number;
    agentsUsed: string[];
    confidence: number;
  };
}

export interface IntentAnalysis {
  intent: 'chat' | 'simple_task' | 'complex_task' | 'unclear';
  confidence: number;
  taskType?: string;
  requiredAgents: ('frontend' | 'backend' | 'devops')[];
  complexity: 'low' | 'medium' | 'high';
  parameters?: Record<string, any>;
}

export enum CommandType {
  // Frontend Commands
  SELECT_TEMPLATE = 'select_template',
  CUSTOMIZE_TEMPLATE = 'customize_template',
  CREATE_COMPONENT = 'create_component',
  UPDATE_COMPONENT = 'update_component',
  CREATE_PAGE = 'create_page',
  UPDATE_STYLING = 'update_styling',
  PERFORMANCE_AUDIT = 'performance_audit',
  ACCESSIBILITY_CHECK = 'accessibility_check',
  RESPONSIVE_DESIGN = 'responsive_design',

  // Backend Commands
  CREATE_API_ENDPOINT = 'create_api_endpoint',
  UPDATE_DATABASE_SCHEMA = 'update_database_schema',
  CREATE_AUTH_SYSTEM = 'create_auth_system',
  OPTIMIZE_DATABASE_QUERIES = 'optimize_database_queries',
  IMPLEMENT_BUSINESS_LOGIC = 'implement_business_logic',
  DATA_VALIDATION = 'data_validation',

  // DevOps Commands
  SETUP_CICD = 'setup_cicd',
  DEPLOY_APPLICATION = 'deploy_application',
  SETUP_MONITORING = 'setup_monitoring',
  OPTIMIZE_INFRASTRUCTURE = 'optimize_infrastructure',
  SECURITY_SCAN = 'security_scan',
  BACKUP_RESTORE = 'backup_restore',

  // Multi-Agent Commands
  CREATE_COMPLETE_WEBSITE = 'create_complete_website',
  IMPLEMENT_FULL_FEATURE = 'implement_full_feature',
  SETUP_FULL_STACK = 'setup_full_stack'
}

export interface Command {
  commandId: string;
  commandType: CommandType;
  payload: {
    description: string;
    target?: string;
    parameters: Record<string, any>;
    userInput?: string;
  };
  priority: 'low' | 'medium' | 'high';
  metadata: {
    timestamp: string;
    userId?: string;
    projectId?: string;
  };
}

/**
 * Unified Orchestrator AI Class
 * ‡∏£‡∏ß‡∏° Chat AI ‡πÅ‡∏•‡∏∞ Orchestrator capabilities
 */
export class OrchestratorAI {
  private llmAdapter: LLMAdapter;
  private conversationHistory: Map<string, ConversationContext>;
  private initialized: boolean = false;

  constructor() {
    this.llmAdapter = new LLMAdapter();
    this.conversationHistory = new Map();
  }

  /**
   * Initialize the orchestrator - ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
   */
  async initialize(): Promise<void> {
    if (this.initialized) return;
    
    try {
      console.log('üîß Initializing Orchestrator AI...');
      await this.llmAdapter.initialize();
      this.initialized = true;
      console.log('‚úÖ Orchestrator AI initialized successfully');
    } catch (error) {
      console.error('‚ùå Failed to initialize Orchestrator AI:', error);
      throw error;
    }
  }

  /**
   * Main entry point - ‡∏£‡∏±‡∏ö user input ‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
   */
  async processUserInput(message: UserMessage): Promise<OrchestratorResponse> {
    const startTime = Date.now();
    
    try {
      console.log('üé≠ Unified Orchestrator AI processing:', message.content);

      // Ensure initialization
      if (!this.initialized) {
        await this.initialize();
      }

      // Get conversation context
      const context = this.getOrCreateContext(message.sessionId || message.userId);
      
      // Update context with new message
      context.previousMessages.push(message.content);
      
      // Analyze user intent
      const analysis = await this.analyzeIntent(message.content, context);
      
      console.log('üß† Intent Analysis:', analysis);

      let response: OrchestratorResponse;

      switch (analysis.intent) {
        case 'chat':
          response = await this.handleChatRequest(message, analysis, context);
          break;
          
        case 'simple_task':
          response = await this.handleSimpleTask(message, analysis, context);
          break;
          
        case 'complex_task':
          response = await this.handleComplexTask(message, analysis, context);
          break;
          
        default:
          response = await this.handleUnclearIntent(message, analysis, context);
          break;
      }

      // Update execution metadata
      response.metadata.executionTime = Date.now() - startTime;
      
      // Store context
      this.conversationHistory.set(message.sessionId || message.userId, context);

      return response;

    } catch (error) {
      console.error('‚ùå Orchestrator AI error:', error);
      return {
        type: 'chat',
        content: '‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á',
        metadata: {
          executionTime: Date.now() - startTime,
          agentsUsed: [],
          confidence: 0
        }
      };
    }
  }

  /**
   * ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå intent ‡∏Ç‡∏≠‡∏á user input
   */
  private async analyzeIntent(
    input: string, 
    context: ConversationContext
  ): Promise<IntentAnalysis> {
    
    // Quick detection ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
    const quickIntent = this.detectQuickIntent(input);
    if (quickIntent) {
      return quickIntent;
    }
    
    const analysisPrompt = this.buildIntentAnalysisPrompt(input, context);
    
    // ‡πÉ‡∏ä‡πâ response config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö intent analysis
    const analysisConfig = getResponseConfig('intentAnalysis');
    const llmOptions = this.getModelSpecificOptions({
      useSystemPrompt: false,
      ...toLLMOptions(analysisConfig)
    });
    
    const response = await this.llmAdapter.callLLM(analysisPrompt, llmOptions);

    try {
      // ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç JSON parsing ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö markdown ‡πÅ‡∏•‡∏∞ empty response
      let jsonContent = response.content?.trim() || '';
      
      // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö empty response
      if (!jsonContent) {
        console.warn('‚ö†Ô∏è Empty response from LLM, using fallback analysis');
        return this.getFallbackAnalysis();
      }
      
      // ‡∏•‡∏ö markdown code blocks ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
      if (jsonContent.includes('```json')) {
        const jsonMatch = jsonContent.match(/```json\s*([\s\S]*?)\s*```/);
        if (jsonMatch) {
          jsonContent = jsonMatch[1].trim();
        }
      } else if (jsonContent.includes('```')) {
        const jsonMatch = jsonContent.match(/```\s*([\s\S]*?)\s*```/);
        if (jsonMatch) {
          jsonContent = jsonMatch[1].trim();
        }
      }
      
      // ‡∏•‡∏≠‡∏á parse JSON
      const analysis = JSON.parse(jsonContent);
      return {
        intent: analysis.intent || 'unclear',
        confidence: analysis.confidence || 0.5,
        taskType: analysis.taskType,
        requiredAgents: analysis.requiredAgents || [],
        complexity: analysis.complexity || 'medium',
        parameters: analysis.parameters || {}
      };
    } catch (error) {
      console.error('‚ùå Failed to parse intent analysis:', error);
      console.error('üìÑ Raw response content:', response.content);
      return this.getFallbackAnalysis();
    }
  }

  /**
   * Fallback analysis ‡πÄ‡∏°‡∏∑‡πà‡∏≠ parse ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
   */
  private getFallbackAnalysis(): IntentAnalysis {
    return {
      intent: 'unclear',
      confidence: 0.3,
      requiredAgents: [],
      complexity: 'medium'
    };
  }

  /**
   * ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö intent ‡∏ó‡∏µ‡πà‡∏á‡πà‡∏≤‡∏¢ ‡πÜ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ AI
   */
  private detectQuickIntent(input: string): IntentAnalysis | null {
    const lowerInput = input.toLowerCase().trim();
    
    // üõ°Ô∏è Security-sensitive requests
    const securityKeywords = [
      '‡∏£‡∏´‡∏±‡∏™ env', 'env key', 'environment variable', 'api key', 'secret key',
      'password', '‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô', 'token', 'credential', 'database password',
      'config file', '‡πÑ‡∏ü‡∏•‡πå config', '.env', 'env file', 'connection string'
    ];
    
    if (securityKeywords.some(keyword => lowerInput.includes(keyword))) {
      return {
        intent: 'chat',
        confidence: 0.95,
        taskType: 'security_denial',
        requiredAgents: [],
        complexity: 'low',
        parameters: { type: 'security_sensitive' }
      };
    }
    
    const mentionsMidori = lowerInput.includes('midori');
    const midoriContextKeywords = ['‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°', 'platform', '‡πÄ‡∏ß‡πá‡∏ö', 'website', '‡∏Ñ‡∏∑‡∏≠', '‡∏≠‡∏∞‡πÑ‡∏£', '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•', '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥', '‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ', '‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå', 'browser'];
    const isMidoriIdentityRequest = mentionsMidori && midoriContextKeywords.some(keyword => lowerInput.includes(keyword));

    if (isMidoriIdentityRequest) {
      return {
        intent: 'chat',
        confidence: 0.92,
        taskType: 'midori_identity',
        requiredAgents: [],
        complexity: 'low',
        parameters: { type: 'midori_identity' }
      };
    }
    
    // ‚è∞ Time/Date queries
    const timeKeywords = ['‡πÄ‡∏ß‡∏•‡∏≤', '‡∏Å‡∏µ‡πà‡πÇ‡∏°‡∏á', '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ', '‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ', '‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ô‡∏µ‡πâ', 'time', 'date', 'now'];
    if (timeKeywords.some(keyword => lowerInput.includes(keyword))) {
      return {
        intent: 'chat',
        confidence: 0.95,
        taskType: 'time_query',
        requiredAgents: [],
        complexity: 'low',
        parameters: { type: 'time_query' }
      };
    }

    // ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠/‡∏ï‡∏±‡∏ß‡∏ï‡∏ô
    if (lowerInput.includes('‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£') || 
        lowerInput.includes('‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£') || 
        lowerInput.includes('‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏±‡∏ß') ||
        lowerInput.includes('what is your name') ||
        lowerInput.includes('who are you')) {
      return {
        intent: 'chat',
        confidence: 0.9,
        taskType: '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏±‡∏ß',
        requiredAgents: [],
        complexity: 'low',
        parameters: { type: 'introduction' }
      };
    }

    // ‡∏Ñ‡∏≥‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢ (‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô)
    if (lowerInput.includes('‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ') || 
        lowerInput.includes('hello') || 
        lowerInput.includes('hi') ||
        lowerInput === '‡πÑ‡∏á' ||
        lowerInput === '‡∏´‡∏ß‡∏±‡∏î‡∏î‡∏µ') {
      return {
        intent: 'chat',
        confidence: 0.9,
        taskType: '‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢',
        requiredAgents: [],
        complexity: 'low',
        parameters: { type: 'greeting' }
      };
    }

    // ‡πÑ‡∏°‡πà‡∏û‡∏ö quick intent
    return null;
  }

  /**
   * Handle pure chat requests
   */
  private async handleChatRequest(
    message: UserMessage,
    analysis: IntentAnalysis,
    context: ConversationContext
  ): Promise<OrchestratorResponse> {
    
    const shortCircuitType = analysis.parameters?.type;

    // ‚è∞ Time/Date queries - ‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ LLM
    if (shortCircuitType === 'time_query') {
      const timeResponse = this.formatCurrentTimeForUser();
      return {
        type: 'chat',
        content: timeResponse,
        metadata: {
          executionTime: 0,
          agentsUsed: [],
          confidence: analysis.confidence
        }
      };
    }

    if (shortCircuitType === 'security_sensitive') {
      const securityResponse = await chatPromptLoader.getPrompt('securityDenial');
      return {
        type: 'chat',
        content: securityResponse,
        metadata: {
          executionTime: 0,
          agentsUsed: [],
          confidence: analysis.confidence
        }
      };
    }

    // üéØ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î response config ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö
    let responseConfigType: string;
    
    if (shortCircuitType === 'greeting') {
      responseConfigType = 'greeting';
    } else if (shortCircuitType === 'introduction') {
      responseConfigType = 'introduction';
    } else if (shortCircuitType === 'midori_identity') {
      responseConfigType = 'midoriIdentity';
    } else if (analysis.taskType === '‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢') {
      responseConfigType = 'greeting';
    } else if (analysis.taskType === '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏±‡∏ß') {
      responseConfigType = 'introduction';
    } else if (context.currentProject && context.lastTaskResult) {
      responseConfigType = 'projectContextAware';
    } else if (context.previousMessages.length > 0) {
      responseConfigType = 'contextAware';
    } else {
      responseConfigType = 'baseChat';
    }

    const chatPrompt = await this.buildChatPrompt(message.content, context, analysis);
    
    // üîç Debug: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ chatPrompt ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏´‡∏°
    console.log(`üîç Generated chatPrompt preview:`, chatPrompt.substring(0, 200));
    console.log(`üéØ Expected introduction prompt should contain: "Midori AI Agent"`);
    console.log(`‚úÖ Does prompt contain expected text?`, chatPrompt.includes('Midori AI Agent'));
    
    // ‡πÉ‡∏ä‡πâ response configuration ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
    const responseConfig = getResponseConfig(responseConfigType);
    const llmOptions = this.getModelSpecificOptions({
      useSystemPrompt: false,
      ...toLLMOptions(responseConfig)
    });
    
    const response = await this.llmAdapter.callLLM(chatPrompt, llmOptions);

    console.log(`‚úÖ Chat response generated using '${responseConfigType}' config:`, {
      tokens: responseConfig.maxCompletionTokens,
      reasoning: responseConfig.reasoning?.effort,
      verbosity: responseConfig.text?.verbosity
    });

    return {
      type: 'chat',
      content: response.content,
      metadata: {
        executionTime: 0, // Will be set by caller
        agentsUsed: [],
        confidence: analysis.confidence
      }
    };
  }

  /**
   * Handle simple tasks (single agent)
   */
  private async handleSimpleTask(
    message: UserMessage,
    analysis: IntentAnalysis,
    context: ConversationContext
  ): Promise<OrchestratorResponse> {
    
    // Create structured command
    const command = this.createCommand(message, analysis);
    
    // Execute via legacy orchestrator
    const taskResult = await legacyOrchestrator(command);
    
    // Generate user-friendly response
    const chatResponse = await this.generateTaskSummary(message.content, taskResult);
    
    return {
      type: 'task',
      content: chatResponse,
      taskResults: taskResult,
      nextSteps: this.generateNextSteps(taskResult),
      metadata: {
        executionTime: 0, // Will be set by caller
        agentsUsed: analysis.requiredAgents,
        confidence: analysis.confidence
      }
    };
  }

  /**
   * Handle complex tasks (multi-agent)
   */
  private async handleComplexTask(
    message: UserMessage,
    analysis: IntentAnalysis,
    context: ConversationContext
  ): Promise<OrchestratorResponse> {
    
    // For complex tasks, use the full orchestrator
    const command = this.createCommand(message, analysis);
    const taskResult = await legacyOrchestrator(command);
    
    // Generate comprehensive response
    const chatResponse = await this.generateTaskSummary(message.content, taskResult);
    
    return {
      type: 'mixed',
      content: chatResponse,
      taskResults: taskResult,
      nextSteps: this.generateNextSteps(taskResult),
      metadata: {
        executionTime: 0, // Will be set by caller
        agentsUsed: analysis.requiredAgents,
        confidence: analysis.confidence
      }
    };
  }

  /**
   * Handle unclear intents
   */
  private async handleUnclearIntent(
    message: UserMessage,
    analysis: IntentAnalysis,
    context: ConversationContext
  ): Promise<OrchestratorResponse> {
    
    try {
      const clarificationPrompt = await chatPromptLoader.getPrompt('unclearIntent', { 
        input: message.content 
      });
      
      return {
        type: 'chat',
        content: clarificationPrompt,
        metadata: {
          executionTime: 0,
          agentsUsed: [],
          confidence: analysis.confidence
        }
      };
    } catch (error) {
      console.error('‚ùå Failed to load unclear intent prompt:', error);
      
      // Fallback clarification message
      const fallbackMessage = `‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ú‡∏°‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö? ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° "${message.content}" ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:
      
1. üó£Ô∏è ‡∏Ñ‡∏∏‡∏¢‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ (‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°, ‡∏Ç‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
2. üé® ‡∏á‡∏≤‡∏ô‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç UI, ‡πÄ‡∏û‡∏¥‡πà‡∏° component)
3. ‚öôÔ∏è ‡∏á‡∏≤‡∏ô‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö (‡∏™‡∏£‡πâ‡∏≤‡∏á API, ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
4. üöÄ ‡∏á‡∏≤‡∏ô‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö deployment (‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ß‡πá‡∏ö, ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏£‡∏∞‡∏ö‡∏ö)

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö üòä`;

      return {
        type: 'chat',
        content: fallbackMessage,
        metadata: {
          executionTime: 0,
          agentsUsed: [],
          confidence: analysis.confidence
        }
      };
    }
  }

  // Helper methods
  private getOrCreateContext(sessionId: string): ConversationContext {
    if (!this.conversationHistory.has(sessionId)) {
      this.conversationHistory.set(sessionId, {
        previousMessages: [],
        activeAgents: [],
      });
    }
    return this.conversationHistory.get(sessionId)!;
  }

  /**
   * ‡∏õ‡∏£‡∏±‡∏ö LLM options ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ model
   */
  private getModelSpecificOptions(options: {
    useSystemPrompt?: boolean;
    temperature?: number;
    maxTokens?: number;
    maxCompletionTokens?: number;
    reasoning?: {
      effort: 'minimal' | 'low' | 'medium' | 'high';
    };
    text?: {
      verbosity: 'low' | 'medium' | 'high';
    };
    model?: string;
  }) {
    // ‡πÉ‡∏ä‡πâ model ‡∏à‡∏≤‡∏Å LLMAdapter ‡∏à‡∏£‡∏¥‡∏á ‡πÜ
    const currentModel = this.llmAdapter.getCurrentModel();
    const constraints = this.llmAdapter.getModelConstraints();
    
    console.log(`ü§ñ Using model: ${currentModel}, constraints:`, constraints);
    
    // ‡∏ñ‡πâ‡∏≤ model ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ default temperature ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    if (constraints.requiresDefaultTemperature) {
      console.log(`‚ö†Ô∏è Model ${currentModel} requires default temperature, removing custom temperature`);
      const { temperature, ...optionsWithoutTemp } = options;
      return optionsWithoutTemp; // ‡πÑ‡∏°‡πà‡∏™‡πà‡∏á temperature parameter
    }
    
    // Models ‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥
    return options;
  }

  private createCommand(message: UserMessage, analysis: IntentAnalysis): Command {
    // Map intent to command type
    let commandType: CommandType;
    
    if (analysis.requiredAgents.includes('frontend')) {
      commandType = CommandType.UPDATE_COMPONENT;
    } else if (analysis.requiredAgents.includes('backend')) {
      commandType = CommandType.CREATE_API_ENDPOINT;
    } else if (analysis.requiredAgents.includes('devops')) {
      commandType = CommandType.DEPLOY_APPLICATION;
    } else {
      commandType = CommandType.CREATE_COMPLETE_WEBSITE;
    }

    return {
      commandId: randomUUID(),
      commandType,
      payload: {
        description: analysis.taskType || message.content,
        target: analysis.parameters?.target,
        parameters: analysis.parameters || {},
        userInput: message.content
      },
      priority: analysis.complexity === 'high' ? 'high' : 'medium',
      metadata: {
        timestamp: new Date().toISOString(),
        userId: message.userId
      }
    };
  }

  private buildIntentAnalysisPrompt(input: string, context: ConversationContext): string {
    return `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå intent ‡∏Ç‡∏≠‡∏á user input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå

**User Input:** "${input}"

**Context:** ${context.previousMessages.slice(-3).join(', ')}

IMPORTANT: ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON object ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ markdown ‡∏´‡∏£‡∏∑‡∏≠ \`\`\`

{
  "intent": "chat|simple_task|complex_task|unclear",
  "confidence": 0.8,
  "taskType": "‡∏™‡∏£‡∏∏‡∏õ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥",
  "requiredAgents": ["frontend", "backend", "devops"],
  "complexity": "low|medium|high",
  "parameters": {
    "key": "value"
  }
}

**Guidelines:**
- **chat**: ‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢, ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°, ‡∏Ç‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥, ‡∏ñ‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠, ‡∏Ñ‡∏∏‡∏¢‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤, ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå (‡πÄ‡∏ä‡πà‡∏ô 1+1), ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå, ‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
- **simple_task**: ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç component ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß, ‡∏™‡∏£‡πâ‡∏≤‡∏á API ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß, ‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏ö feature ‡πÄ‡∏•‡πá‡∏Å‡πÜ
- **complex_task**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡πÉ‡∏´‡∏°‡πà, ‡∏£‡∏∞‡∏ö‡∏ö‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô, ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
- **unclear**: ‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£

**Chat Examples (‡πÉ‡∏ä‡πâ chat ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô):**
- "1+1 ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà", "5*3 ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà"
- "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "hello", "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£"
- "React ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£", "Supabase ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ"
- "‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°"
- "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á", "‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£"`;
  }

  /**
   * Build chat prompt using prompt loader
   */
  private async buildChatPrompt(
    input: string, 
    context: ConversationContext, 
    analysis?: IntentAnalysis
  ): Promise<string> {
    try {
      console.log(`üé≠ buildChatPrompt called with analysis:`, analysis?.parameters);
      
      // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
      const lowerInput = input.toLowerCase();
      const shortCircuitType = analysis?.parameters?.type;
      
      // üõ°Ô∏è Security-sensitive requests
      if (analysis?.parameters?.type === 'security_sensitive') {
        console.log(`üõ°Ô∏è Using security denial prompt`);
        return await chatPromptLoader.getPrompt('securityDenial');
      }
      
      const midoriIdentityKeywords = ['‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°', 'platform', '‡πÄ‡∏ß‡πá‡∏ö', 'website', '‡∏Ñ‡∏∑‡∏≠', '‡∏≠‡∏∞‡πÑ‡∏£', '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•', '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥', '‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ', '‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå', 'browser'];
      const shouldUseMidoriIdentity =
        analysis?.parameters?.type === 'midori_identity' ||
        (lowerInput.includes('midori') && midoriIdentityKeywords.some(keyword => lowerInput.includes(keyword)));

      if (shouldUseMidoriIdentity) {
        console.log(`üåø Using midori identity prompt`);
        return await chatPromptLoader.getPrompt('midoriIdentity', { input });
      }

      // Introduction/Self-identification
      if (lowerInput.includes('‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£') || 
          lowerInput.includes('‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£') || 
          lowerInput.includes('‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏±‡∏ß') ||
          lowerInput.includes('‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏Ñ‡∏£') ||
          lowerInput.includes('‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£') ||
          (analysis?.parameters?.type === 'introduction')) {
        
        console.log(`üéØ Using introduction prompt for input: "${input}"`);
        try {
          const prompt = await chatPromptLoader.getPrompt('introduction', { input });
          console.log(`üìù Introduction prompt loaded: ${prompt.substring(0, 100)}...`);
          return prompt;
        } catch (error) {
          console.error(`‚ùå Failed to load introduction prompt:`, error);
          return this.getFallbackChatPrompt(input);
        }
      }
      
      // Greeting (‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô)
      if (lowerInput.includes('‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ') || 
          lowerInput.includes('hello') || 
          lowerInput.includes('hi') ||
          lowerInput === '‡πÑ‡∏á' ||
          lowerInput === '‡∏´‡∏ß‡∏±‡∏î‡∏î‡∏µ' ||
          (analysis?.parameters?.type === 'greeting')) {
        return await chatPromptLoader.getPrompt('greeting');
      }
      
      // Technology questions
      if (lowerInput.includes('‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ') || 
          lowerInput.includes('react') || 
          lowerInput.includes('supabase') ||
          lowerInput.includes('vite')) {
        return await chatPromptLoader.getPrompt('technologyExplanation', { input });
      }
      
      // Project context aware (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ project context)
      if (context.currentProject && context.lastTaskResult) {
        return await chatPromptLoader.getPrompt('projectContextAware', { 
          input, 
          projectName: context.currentProject,
          recentWork: JSON.stringify(context.lastTaskResult).substring(0, 200) + '...'
        });
      }
      
      // Context-aware (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ conversation history)
      if (context.previousMessages.length > 0) {
        const recentMessages = context.previousMessages.slice(-3).join(', ');
        return await chatPromptLoader.getPrompt('contextAware', { 
          input, 
          context: recentMessages 
        });
      }
      
      // Default base chat prompt
      return await chatPromptLoader.getPrompt('base', { input });
      
    } catch (error) {
      console.error('‚ùå Failed to load chat prompt, using fallback:', error);
      return this.getFallbackChatPrompt(input);
    }
  }

  /**
   * Fallback chat prompt ‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
   */
  private getFallbackChatPrompt(input: string): string {
    return `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô Midori AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏î‡∏µ

User ‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤: "${input}"

‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå

**‡∏´‡∏≤‡∏Å‡∏ñ‡∏π‡∏Å‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏ï‡∏ô/‡∏ä‡∏∑‡πà‡∏≠:**
- ‡∏ä‡∏∑‡πà‡∏≠: Midori AI
- ‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó: ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ: ‡∏™‡∏£‡πâ‡∏≤‡∏á UI, API, Deploy ‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå

**‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å:**
- Vite + React + TypeScript
- Supabase (Database + Auth)
- ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 100 ‡∏Ñ‡∏≥)`;
  }

  private async generateTaskSummary(input: string, taskResult: any): Promise<string> {
    const summaryPrompt = `‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡πâ user ‡∏ü‡∏±‡∏á‡πÅ‡∏ö‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢:

User ‡∏Ç‡∏≠: "${input}"

‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ${JSON.stringify(taskResult, null, 2)}

‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏ö‡πâ‡∏≤‡∏á (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 80 ‡∏Ñ‡∏≥)`;

    try {
      // ‡πÉ‡∏ä‡πâ task summary config
      const summaryConfig = getResponseConfig('taskSummary');
      const llmOptions = this.getModelSpecificOptions({
        useSystemPrompt: false,
        ...toLLMOptions(summaryConfig)
      });
      
      const response = await this.llmAdapter.callLLM(summaryPrompt, llmOptions);
      return response.content;
    } catch (error) {
      return `‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö! ‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Ç‡∏≠‡πÅ‡∏•‡πâ‡∏ß`;
    }
  }

  private generateNextSteps(taskResult: any): string[] {
    // Simple next steps generation
    if (taskResult?.plan?.tasks) {
      return ['‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô', '‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£', '‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå'];
    }
    return ['‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡∏π', '‡πÅ‡∏à‡πâ‡∏á‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤'];
  }

  /**
   * Format current time for user query
   */
  private formatCurrentTimeForUser(tz?: string): string {
    const timezone = tz || process.env.TZ || 'Asia/Bangkok';
    const now = new Date();
    
    const formatter = new Intl.DateTimeFormat('th-TH', {
      timeZone: timezone,
      weekday: 'long',
      year: 'numeric',
      month: 'long', 
      day: 'numeric',
      hour: '2-digit',
      minute: '2-digit',
      second: '2-digit',
      timeZoneName: 'short'
    });
    
    const formattedTime = formatter.format(now);
    return `‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠ ${formattedTime} ‡∏Ñ‡∏£‡∏±‡∏ö`;
  }
}

// Global orchestrator instance ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á initialize ‡∏ã‡πâ‡∏≥
let globalOrchestrator: OrchestratorAI | null = null;

/**
 * Helper function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô - ‡πÉ‡∏ä‡πâ singleton pattern
 */
export async function processUserMessage(
  content: string,
  userId: string = 'default-user',
  sessionId?: string
): Promise<OrchestratorResponse> {
  // ‡πÉ‡∏ä‡πâ global instance ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
  if (!globalOrchestrator) {
    globalOrchestrator = new OrchestratorAI();
    await globalOrchestrator.initialize();
  }
  
  const message: UserMessage = {
    content,
    userId,
    sessionId: sessionId || userId,
    timestamp: new Date().toISOString()
  };

  return await globalOrchestrator.processUserInput(message);
}